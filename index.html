<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Vais - Smart Navigation Pro</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body {
      background: #0d0d0d;
      color: #00eaff;
      font-family: 'Segoe UI', sans-serif;
      margin: 0;
      padding: 0;
    }
    header {
      background: #111;
      padding: 15px;
      text-align: center;
      font-size: 1.5em;
      color: #00d4ff;
      border-bottom: 2px solid #00d4ff;
    }
    #canvas-container {
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 20px;
    }
    canvas {
      border: 3px solid #00eaff;
      border-radius: 12px;
      box-shadow: 0 0 15px #00eaff55;
      background: #1a1a1a;
    }
    #subtitles {
      margin-top: 12px;
      font-size: 1.2em;
      background: #111;
      padding: 10px 20px;
      border-radius: 10px;
      color: #fff;
      box-shadow: 0 0 12px #00eaff33;
      text-align: center;
      width: 90%;
      max-width: 680px;
    }
    video {
      display: none;
    }
  </style>
</head>
<body>
  <header>Vais - Smart Navigation Pro</header>
  <div id="canvas-container">
    <video id="video" width="640" height="480" autoplay muted playsinline></video>
    <canvas id="canvas1" width="640" height="480"></canvas>
    <div id="subtitles">Loading AI model...</div>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas1');
    const ctx = canvas.getContext('2d');
    const subtitles = document.getElementById('subtitles');

    let model, lastGuidance = '', lastSpoken = 0, speaking = false;
    const speakCooldown = 4000, repeatCooldown = 12000;

    async function init() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.onloadedmetadata = () => video.play();
      } catch (err) {
        subtitles.textContent = "Camera access denied.";
        return;
      }

      model = await cocoSsd.load();
      subtitles.textContent = "Environment scanning initialized.";
      setInterval(processFrame, 1000);
    }

    async function processFrame() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const predictions = await model.detect(video);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const detected = [];

      for (let pred of predictions) {
        const [x, y, w, h] = pred.bbox;
        ctx.fillStyle = 'rgba(0, 234, 255, 0.3)';
        ctx.fillRect(x, y, w, h);
        ctx.fillStyle = '#ffffff';
        ctx.font = '16px Segoe UI';
        ctx.fillText(pred.class, x, y - 8);

        const direction = getDirection(x);
        const meters = estimateDistanceMeters(h);
        detected.push({ label: pred.class, direction, meters });
      }

      if (detected.length) {
        const guidance = createGuidance(detected);
        const now = Date.now();
        if ((guidance !== lastGuidance && now - lastSpoken > speakCooldown) ||
            (now - lastSpoken > repeatCooldown)) {
          say(guidance);
          lastSpoken = now;
          lastGuidance = guidance;
        }
      } else {
        subtitles.textContent = "No objects detected.";
      }
    }

    function getDirection(x) {
      if (x < canvas.width / 3) return 'left';
      if (x < (2 * canvas.width) / 3) return 'center';
      return 'right';
    }

    function estimateDistanceMeters(boxHeight, realHeight = 1.6, focalLength = 600) {
      if (boxHeight <= 0) return 10;
      const distance = (realHeight * focalLength) / boxHeight;
      return Math.min(Math.round(distance * 10) / 10, 10);
    }

    function createGuidance(objects) {
      const sentences = objects.map(obj =>
        `a ${obj.label} around ${obj.meters} feet${obj.meters > 1 ? 's' : ''} to your ${obj.direction}`);
      if (sentences.length === 1) return `There is ${sentences[0]}.`;
      if (sentences.length === 2) return `There is ${sentences[0]} and ${sentences[1]}.`;
      return `I see ${sentences.slice(0, -1).join(', ')}, and ${sentences.at(-1)}.`;
    }

    function say(text) {
      if (speaking) return;
      speaking = true;
      subtitles.textContent = text;
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';
      utterance.pitch = 1.1;
      utterance.rate = 1;
      utterance.volume = 0.9;
      utterance.onend = () => speaking = false;
      speechSynthesis.cancel();
      speechSynthesis.speak(utterance);
    }

    init();
  </script>
</body>
</html>
